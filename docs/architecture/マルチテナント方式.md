### **アーキテクチャ方針 v1.1**

**文書ID:** `ARC-003`
**文書名:** `マルチテナント方式`

| Ver | 日付 | 作成 / 変更者 | 変更概要 |
|-----|------|---------------|----------|
| 1.0 | 2025-06-30 | システム管理者 | 初版作成 |
| 1.1 | 2025-06-30 | システム管理者 | バージョン管理追加、バックアップ/リストア戦略追記 |

---

### 1. はじめに

本システムは、複数の不動産事業者（テナント）が独立して利用することを前提としたSaaS (Software as a Service) である。マルチテナントアーキテクチャは、単一のアプリケーションインスタンスで複数のテナントをサポートするための基盤であり、その方式選定はシステムのセキュリティ、スケーラビリティ、運用コスト、将来の拡張性に重大な影響を与える。

本ドキュメントは、本システムで採用するデータベースのテナント分離モデルを定義し、その実装方針を定めるものである。

### 2. テナント分離モデルの比較検討

テナントのデータを分離・管理する方式として、主要な3つのモデルを比較検討する。

| モデル名 | 概要 | メリット | デメリット |
| :--- | :--- | :--- | :--- |
| **1. データベース分離モデル**<br>(Database-per-tenant) | テナントごとに完全に独立したデータベースインスタンスを用意する。 | ・テナント間のデータ分離が物理的で最も強固。<br>・テナントごとのバックアップ/リストアが容易。<br>・テナント固有のカスタマイズがしやすい。 | ・テナント数が増えるとDBインスタンス数が膨大になり、コストと運用負荷が最も高い。<br>・新規テナントのプロビジョニングに時間がかかる。 |
| **2. スキーマ分離モデル**<br>(Schema-per-tenant) | 単一のデータベースインスタンス内で、テナントごとに異なるスキーマ（テーブルの集合）を作成してデータを分離する。 | ・単一DBのため、運用・リソースコストを抑えられる。<br>・データ分離が論理的に強固。<br>・テナントごとのバックアップ/リストアが比較的容易。<br>・テナントごとのテーブル構造カスタマイズが可能。 | ・アプリケーション側で、リクエストに応じて適切なスキーマに接続を切り替えるロジックが必要。<br>・DBによっては、スキーマ数が数千を超えるとパフォーマンスに影響が出る可能性がある。 |
| **3. テーブル共有モデル**<br>(Shared-table) | 全テナントが全てのテーブルを共有し、各テーブルに`tenant_id`カラムを追加してデータを区別する。 | ・最もリソース効率が良く、運用コストが低い。<br>・新規テナントの追加が容易（`tenants`テーブルへのレコード追加のみ）。<br>・全テナントに共通の機能改修を適用しやすい。 | ・アプリケーションの全てのクエリで`tenant_id`による絞り込みが必須となり、実装ミスが重大なデータ漏洩に繋がる。<br>・テナントごとのカスタマイズが困難。<br>・バックアップ/リストアがテナント単位で困難。 |

### 3. 採用方針の決定

**結論: 本システムでは「2. スキーマ分離モデル（Schema-per-tenant）」を採用する。**

#### 3.1. 採用理由

- **データ独立性とセキュリティのバランス:** 物理的なデータベース分離ほどではないが、スキーマレベルでの分離は論理的に強固であり、テナント間のデータ漏洩リスクを大幅に低減できる。これは、顧客の機密情報を扱う本システムの要件と合致する。
- **コスト効率:** データベースインスタンスをテナントごとに用意する必要がなく、サーバーリソースとライセンスコストを効率的に利用できる。
- **将来の拡張性:** 将来的に特定の巨大テナント（スーパープレミアムプランなど）が登場した場合、そのテナントだけを物理的な別データベースに移行させる（ハイブリッドモデルへの移行）といった柔軟な対応が可能である。
- **運用性:** テナントごとのバックアップやデータ移行が、テーブル共有モデルに比べて格段に容易である。

テーブル共有モデルは、実装のわずかなミスが致命的な情報漏洩に繋がるリスクを常に内包しており、本システムの性質上、許容できないと判断した。

### 4. 実装上の考慮点

スキーマ分離モデルを実装するにあたり、以下の点を考慮する。

- **4.1. テナント識別**
  - ユーザー認証後、発行されるJWT (JSON Web Token) のペイロードに`tenant_id`を含める。
  - アプリケーションは、APIリクエストの都度、JWTから`tenant_id`を抽出し、そのリクエストがどのテナントに属するかを識別する。

- **4.2. データベース接続管理**
  - アプリケーションは、リクエストから`tenant_id`を識別した後、PostgreSQLの`SEARCH_PATH`を動的に設定することで、後続のクエリが適切なテナントのスキーマに対して実行されるように制御する。
  - これにより、アプリケーションのデータアクセス層（リポジトリパターン等）は、`tenant_id`を意識することなく記述できる。

- **4.3. 新規テナントのプロビジョニング**
  - 新規テナント（企業）が契約・登録されると、以下のプロセスが自動的に実行される。
    1. 新しいテナントID (`UUID`) を発行する。
    2. そのテナントIDを名前とする新しいスキーマ（例: `tenant_a1b2c3d4`）をデータベース内に作成する。
    3. 最新のテーブル定義（DDL）をそのスキーマ内に展開する。
    4. テナント管理者（`tenant_admin`）の初期アカウントを作成する。

- **4.4. 共有データと管理スキーマ**
  - 全テナントで共通の情報（システム設定、プラン情報など）や、テナント自体の情報を管理するテーブルは、`public`スキーマや`shared`スキーマといった共有領域に配置する。
  - アプリケーションは、共有データにアクセスする際は明示的に共有スキーマを指定してクエリを実行する。

### 5. バックアップ/リストア戦略

スキーマ分離モデルにおけるテナント単位でのバックアップ・復旧戦略を以下に定義する。

#### 5.1. バックアップ戦略

- **5.1.1. 全体バックアップ**
  - データベース全体（全テナントスキーマ + 共有スキーマ）の論理バックアップを、`pg_dump`を使用して日次で実行する。
  - バックアップファイルは、暗号化してGoogle Cloud Storage等のオブジェクトストレージに保存し、地理的に分散した複数リージョンにレプリケーションする。
  - 保持期間：日次バックアップは30日間、週次バックアップは12週間、月次バックアップは12ヶ月間。

- **5.1.2. テナント個別バックアップ**
  - 特定のテナントのみを対象とした論理バックアップを、要求に応じて実行できる仕組みを構築する。
  - PostgreSQLの`--schema`オプションを使用して、指定テナントのスキーマのみを抽出する。
  - 大規模テナントや重要顧客については、追加のバックアップ頻度設定が可能とする。

#### 5.2. リストア戦略

- **5.2.1. 全体復旧**
  - システム全体の障害時は、最新の全体バックアップから完全復旧を実行する。
  - 復旧手順は以下の通り：
    1. 新しいPostgreSQLインスタンスを起動
    2. `pg_restore`を使用してバックアップファイルから全データを復元
    3. アプリケーションサーバーの接続先を更新
    4. 整合性チェックとシステム動作確認

- **5.2.2. テナント個別復旧**
  - 特定テナントのみのデータ破損・誤操作時は、該当テナントスキーマのみを部分復旧する。
  - 復旧手順は以下の通り：
    1. 影響を受けたテナントスキーマを一時的に`_backup`接尾辞で退避
    2. 新しいテナントスキーマを作成
    3. テナント個別バックアップまたは全体バックアップから該当スキーマのみを復元
    4. データ整合性チェック実行
    5. アプリケーション側でテナントアクセスを復旧

#### 5.3. 災害復旧(DR)対応

- **RPO (Recovery Point Objective)**: 1時間（最大1時間前のデータまで復旧可能）
- **RTO (Recovery Target Objective)**: 4時間（障害発生から4時間以内に復旧完了）
- 地理的に分散したGoogle Cloudの異なるAvailability Zoneにスタンバイ環境を構築し、PostgreSQLのストリーミングレプリケーションによる準リアルタイム同期を実施する。 